{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset\n",
    "import datetime\n",
    "from geographiclib.geodesic import Geodesic\n",
    "plt.rcParams['figure.max_open_warning'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载训练数据\n",
    "train_dataset = pd.read_csv(\"train.csv\",parse_dates = [[\"date\",\"time\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.靠近岸边\n",
    "del1 = [305808, 717484, 843052, 803514, 996179, 477271, 370548, 460277,768635]\n",
    "#2.长度不足\n",
    "del2 = [451328,742548,640706,65874,996179,831336,316790]\n",
    "#3.断点\n",
    "del3 = [607240]\n",
    "del_all = list(set(del1).union(set(del2)).union(set(del3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#筛选数据集\n",
    "train_dataset = train_dataset[~train_dataset.id.isin(del_all)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPS_filter(data,lon,lat,num):\n",
    "    dis_step = data[\"lat\"].diff().abs().mean().mean()\n",
    "    distance = 0.5*dis_step*(num**0.5)\n",
    "    GPSfilter = (data[\"lat\"]>lat-distance) & (data[\"lat\"]<lat+distance) & (data[\"lon\"]>lon-distance) & (data[\"lon\"]<lon+distance)\n",
    "    while GPSfilter.sum().sum()!=num:\n",
    "        if GPSfilter.sum().sum()>num:\n",
    "            max_dis = [data[\"lat\"][GPSfilter].max().max()-lat,\n",
    "                        data[\"lon\"][GPSfilter].max().max()-lon,\n",
    "                        lat-data[\"lat\"][GPSfilter].min().min(),\n",
    "                        lon-data[\"lon\"][GPSfilter].min().min()]\n",
    "            distance = max(max_dis)\n",
    "            GPSfilter_range = (data[\"lat\"]>lat-distance) & (data[\"lat\"]<lat+distance) & (data[\"lon\"]>lon-distance) & (data[\"lon\"]<lon+distance)\n",
    "            GPSfilter_range = GPSfilter ^ GPSfilter_range\n",
    "            GPSfilter_range_num = len(np.where(GPSfilter_range)[0])          \n",
    "            if GPSfilter_range_num>1 and (GPSfilter.sum().sum()-num)<GPSfilter_range_num:\n",
    "                range_num = num+GPSfilter_range_num-GPSfilter.sum().sum()\n",
    "                GPSfilter = (data[\"lat\"]>lat-distance) & (data[\"lat\"]<lat+distance) & (data[\"lon\"]>lon-distance) & (data[\"lon\"]<lon+distance)\n",
    "                coord = np.where(GPSfilter_range)\n",
    "                #print(range_num)  \n",
    "                for i in range(range_num):\n",
    "                    GPSfilter.iloc[coord[0][i], coord[1][i]] = True\n",
    "            else:\n",
    "                    GPSfilter = (data[\"lat\"]>lat-distance) & (data[\"lat\"]<lat+distance) & (data[\"lon\"]>lon-distance) & (data[\"lon\"]<lon+distance)\n",
    "        elif GPSfilter.sum().sum()<num:\n",
    "            distance = distance +dis_step*0.0999\n",
    "            GPSfilter = (data[\"lat\"]>lat-distance) & (data[\"lat\"]<lat+distance) & (data[\"lon\"]>lon-distance) & (data[\"lon\"]<lon+distance)\n",
    "        #print(GPSfilter.sum().sum())\n",
    "    return GPSfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54720it [1:35:43,  9.53it/s]\n"
     ]
    }
   ],
   "source": [
    "#风场\n",
    "wd_u_avg = []\n",
    "wd_v_avg = []\n",
    "from tqdm import tqdm\n",
    "for index, row in tqdm(train_dataset.iterrows()):\n",
    "    date_temp = row.date_time + datetime.timedelta(hours=-20) #风场\n",
    "    hour_temp = date_temp.hour\n",
    "    if date_temp.strftime(\"%Y%m%d\") not in [\"20191221\",\"20200319\"]:\n",
    "        wd=Dataset('wind/wind_hour_%s12.nc' % date_temp.strftime(\"%Y%m%d\"))\n",
    "    else:\n",
    "        date_temp = date_temp + datetime.timedelta(hours=-24)\n",
    "        hour_temp = date_temp.hour + 24\n",
    "        wd=Dataset('wind/wind_hour_%s12.nc' % date_temp.strftime(\"%Y%m%d\"))\n",
    "    wd_lon = wd.variables['LONGITUDE1_151'][:].data\n",
    "    wd_lat = wd.variables['LATITUDE1_151'][:].data\n",
    "    wd_u = wd.variables['U10'][:].data[hour_temp]\n",
    "    wd_v = wd.variables['V10'][:].data[hour_temp]\n",
    "    wd_db = pd.DataFrame(np.zeros(((wd_u.shape[0], wd_u.shape[1]*4))),index=list(range(wd_u.shape[0])),columns=[[\"lat\"]*wd_u.shape[1]+[\"lon\"]*wd_u.shape[1]+[\"u\"]*wd_u.shape[1]+[\"v\"]*wd_u.shape[1],list(range(wd_u.shape[1]))*4])\n",
    "    wd_db[\"lat\"] = wd_lat\n",
    "    wd_db[\"lon\"] = wd_lon\n",
    "    wd_db[\"lon\"] = wd_db[\"lon\"].T\n",
    "    wd_db[\"u\"] = wd_u\n",
    "    wd_db[\"v\"] = wd_v\n",
    "    GPS_sub4 = GPS_filter(wd_db,row.lng,row.lat,4)\n",
    "    dis_weights = []\n",
    "    for i in zip(wd_db[\"lon\"][GPS_sub4].unstack().dropna(how='all'),wd_db[\"lat\"][GPS_sub4].unstack().dropna(how='all')):\n",
    "        dis_weights.append(1/Geodesic.WGS84.Inverse(row.lat,row.lng,i[1], i[0])[\"s12\"])\n",
    "    wd_u_avg.append(np.average(wd_db[\"u\"][GPS_sub4].unstack().dropna(how='all'),weights = dis_weights))\n",
    "    wd_v_avg.append(np.average(wd_db[\"v\"][GPS_sub4].unstack().dropna(how='all'),weights = dis_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[\"wd_u_avg\"] = wd_u_avg\n",
    "train_dataset[\"wd_v_avg\"] = wd_v_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_csv(\"temp1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54720it [4:28:25,  3.40it/s]\n"
     ]
    }
   ],
   "source": [
    "#洋流\n",
    "Oflow_u_avg = []\n",
    "Oflow_v_avg = []\n",
    "from tqdm import tqdm\n",
    "for index, row in tqdm(train_dataset.iterrows()):\n",
    "    date_temp = row.date_time + datetime.timedelta(hours=-8) #洋流\n",
    "    hour_temp = date_temp.hour\n",
    "    Oflow=Dataset('current/current_hour_%s.nc' % date_temp.strftime(\"%Y%m%d\"))\n",
    "    Oflow_lon = Oflow.variables['lon'][:].data.T  # 经度间隔0.005度\n",
    "    Oflow_lat = Oflow.variables['lat'][:].data.T   # 纬度间隔0.01度\n",
    "    Oflow_u = Oflow.variables['u'][:].data[hour_temp][0].T\n",
    "    Oflow_v = Oflow.variables['v'][:].data[hour_temp][0].T\n",
    "    Oflow_db = pd.DataFrame(np.zeros(((Oflow_u.shape[0], Oflow_u.shape[1]*4))),index=list(range(Oflow_u.shape[0])),columns=[[\"lat\"]*Oflow_u.shape[1]+[\"lon\"]*Oflow_u.shape[1]+[\"u\"]*Oflow_u.shape[1]+[\"v\"]*Oflow_u.shape[1],list(range(Oflow_u.shape[1]))*4])\n",
    "    Oflow_db[\"lat\"] = Oflow_lat\n",
    "    Oflow_db[\"lon\"] = Oflow_lon\n",
    "    Oflow_db[\"u\"] = Oflow_u\n",
    "    Oflow_db[\"v\"] = Oflow_v\n",
    "    \n",
    "    GPS_sub9 = GPS_filter(Oflow_db,row.lng,row.lat,4)\n",
    "    dis_weights = []\n",
    "    for i in zip(Oflow_db[\"lon\"][GPS_sub9].unstack().dropna(how='all'),Oflow_db[\"lat\"][GPS_sub9].unstack().dropna(how='all')):\n",
    "        dis_weights.append(1/Geodesic.WGS84.Inverse(row.lat,row.lng,i[1], i[0])[\"s12\"])\n",
    "    Oflow_u_avg.append(np.average(Oflow_db[\"u\"][GPS_sub9].unstack().dropna(how='all'),weights = dis_weights))\n",
    "    Oflow_v_avg.append(np.average(Oflow_db[\"v\"][GPS_sub9].unstack().dropna(how='all'),weights = dis_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[\"Oflow_u_avg\"] = Oflow_u_avg\n",
    "train_dataset[\"Oflow_v_avg\"] = Oflow_v_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_csv(\"temp2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#位移\n",
    "train_dataset.reset_index(inplace = True)\n",
    "move_u = []\n",
    "move_v = []\n",
    "for i in range(train_dataset.shape[0]-1):\n",
    "    if train_dataset.id[i] == train_dataset.id[i+1]:\n",
    "        distance = Geodesic.WGS84.Inverse(train_dataset.lat[i],train_dataset.lng[i],train_dataset.lat[i+1],train_dataset.lng[i+1])\n",
    "        move_u.append(distance[\"s12\"] * math.sin(math.radians(distance[\"azi1\"]))) #move_u: 位移东向向量\n",
    "        move_v.append(distance[\"s12\"] * math.cos(math.radians(distance[\"azi1\"]))) #move_v: 位移北向向量\n",
    "    else:\n",
    "        move_u.append(np.nan)\n",
    "        move_v.append(np.nan)\n",
    "move_u.append(np.nan)\n",
    "move_v.append(np.nan)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[\"move_u\"] = move_u\n",
    "train_dataset[\"move_v\"] = move_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_index(\"index\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_csv(\"temp3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
